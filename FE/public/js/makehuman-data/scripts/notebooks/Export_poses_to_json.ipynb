{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:04:56.354089",
     "start_time": "2016-12-12T17:04:56.052001"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "import json\n",
    "from path import Path\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "basedir=r'/media/isisilon/Data/My_Documents/Documents/eclipse-workspace/bb2/mhwebui2/mhwebui2/scripts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import makehuman-cmd\n",
    "\n",
    "https://bitbucket.org/duststorm01/makehuman-commandline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:04:58.462127",
     "start_time": "2016-12-12T17:04:57.947192"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized logging\n"
     ]
    }
   ],
   "source": [
    "# from .mh_helpers import clean, short_hash, clean_modifier\n",
    "\n",
    "mhpath = Path(os.path.abspath(\"../vendor/makehuman-commandline/makehuman\"))\n",
    "\n",
    "#===============================================================================\n",
    "# Import Makehuman resources, needs to be with makehuman dir as current dir\n",
    "#===============================================================================\n",
    "\n",
    "appcwd = os.path.abspath(os.curdir)\n",
    "sys.path.append(mhpath)\n",
    "sys.path.append(appcwd)\n",
    "sys.path.append('.')\n",
    "\n",
    "with mhpath:\n",
    "    import makehuman\n",
    "    oldpath = os.sys.path\n",
    "    makehuman.set_sys_path()\n",
    "    # make makehuman paths absolute by going through newest paths and making abs\n",
    "    for i in range(len(os.sys.path)):\n",
    "        p = os.sys.path[i]\n",
    "        if p[0:2] == './':\n",
    "            os.sys.path[i] = os.path.join(\n",
    "                os.path.abspath('.'), p.replace('./', ''))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    makehuman.init_logging()\n",
    "    logging.getLogger().setLevel(logging.CRITICAL)\n",
    "    #import image_pil as image_lib\n",
    "    #\n",
    "    import proxy as mhproxy\n",
    "    import humanargparser\n",
    "    import targets as mhtargets\n",
    "    from human import Human\n",
    "    import files3d\n",
    "    import getpath\n",
    "    import humanmodifier\n",
    "    from core import G\n",
    "    import headless\n",
    "    import autoskinblender\n",
    "    import export\n",
    "    \n",
    "    # Init console app\n",
    "    with mhpath:\n",
    "        G.app = headless.ConsoleApp()\n",
    "#     G.app.selectedHuman = human = getHuman()\n",
    "    headless.OBJExporter = None\n",
    "    headless.MHXExporter = None\n",
    "    headless.MhxConfig = None\n",
    "    humanargparser.mods_loaded = False\n",
    "    \n",
    "    from makehuman import LicenseInfo\n",
    "    mh_licence=LicenseInfo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-19T14:49:50.987048",
     "start_time": "2016-11-19T14:49:50.983976"
    },
    "collapsed": true
   },
   "source": [
    "# Export poses\n",
    "\n",
    "We export the rotation matrix for each bone in each pose to json. Then they can be loaded into three.js with\n",
    "```js\n",
    "bone.setFromRotationMatrix(m)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:05:13.713420",
     "start_time": "2016-12-12T17:05:13.698648"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'data/poses/fly02.bvh',\n",
       " u'data/poses/fight01.bvh',\n",
       " u'data/poses/fight02.bvh',\n",
       " u'data/poses/fight03.bvh',\n",
       " u'data/poses/fight04.bvh',\n",
       " u'data/poses/fly01.bvh',\n",
       " u'data/poses/run01.bvh',\n",
       " u'data/poses/sit01.bvh',\n",
       " u'data/poses/standing01.bvh',\n",
       " u'data/poses/standing02.bvh',\n",
       " u'data/poses/standing03.bvh',\n",
       " u'data/poses/standing04.bvh',\n",
       " u'data/poses/standing05.bvh',\n",
       " u'data/poses/standing06.bvh',\n",
       " u'data/poses/tpose.bvh',\n",
       " u'data/poses/gym01.bvh',\n",
       " u'data/poses/mh-rigging351-benchmark1.bvh',\n",
       " u'data/poses/arms_akimbo/akimbo01.bvh',\n",
       " u'data/poses/prostrate/prostrate01.bvh',\n",
       " u'data/poses/sitting-pose/sitting.bvh',\n",
       " u'data/poses/sit_on_ground_01/sit_on_ground01.bvh',\n",
       " u'data/poses/snorkel_diver_01/Snorkel_Diver_01.bvh',\n",
       " u'data/poses/genuflect/genuflect01.bvh',\n",
       " u'data/poses/harvey_fashioncloseup2/Harvey_FashionCloseup2.bvh',\n",
       " u'data/poses/harvey_fashionclosup1/Harvey_FashionCloseup1.bvh',\n",
       " u'data/poses/harvey_fightpose1/Harvey_Fightpose1.bvh',\n",
       " u'data/poses/harvey_fightpose2/Harvey_Fightpose2.bvh',\n",
       " u'data/poses/harvey_idunno/Harvey_IDunno.bvh',\n",
       " u'data/poses/harvey_selfie1/Harvey_selfie1.bvh',\n",
       " u'data/poses/harvey_sittingfashion1/Harvey_sittingfashion1.bvh',\n",
       " u'data/poses/harvey_sittingfashion2/Harvey_SittingFashion2.bvh',\n",
       " u'data/poses/harvey_standingfashion1/Harvey_StandingFashion1.bvh',\n",
       " u'data/poses/harvey_standingfashion2/Harvey_StandingFashion2.bvh',\n",
       " u'data/poses/harvey_standingfashion3/Harvey_StandingFashion3.bvh',\n",
       " u'data/poses/harvey_super1/Harvey_Super1.bvh',\n",
       " u'data/poses/harvey_super2/Harvey_Super2.bvh',\n",
       " u'data/poses/lie_pensive_01/lie_pensive_01.bvh']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bvh\n",
    "pose_files = list(getpath.search(['data/poses'], ['.bvh'], True))\n",
    "pose_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:08:17.590985",
     "start_time": "2016-12-12T17:08:17.588346"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data={}\n",
    "# for pose_file in pose_files:\n",
    "#     bvh_obh = bvh.load(pose_file)\n",
    "#     pose_data=data[bvh_obh.name]={}\n",
    "#     for bone in bvh_obh.bvhJoints:\n",
    "#         m=np.identity(4, dtype=np.float32)\n",
    "#         m[:3]=bone.matrixPoses\n",
    "#         pose_data[bone.name]=m.flatten().tolist()\n",
    "    \n",
    "\n",
    "# json.dump(data,open('/tmp/poses.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-29T11:36:44.390334",
     "start_time": "2016-11-29T11:36:44.386355"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # # no doesn't work\n",
    "# data={}\n",
    "# pose_files = list(getpath.search(['data/poses'], ['.bvh'], True))\n",
    "# for pose_file in pose_files:\n",
    "#     bvh_obh = bvh.load(pose_file)\n",
    "#     pose_data=data[bvh_obh.name]={}\n",
    "#     for bone in bvh_obh.bvhJoints:\n",
    "#         m=bone.matRestRelative\n",
    "#         pose_data[bone.name]=m.flatten().tolist()\n",
    "    \n",
    "\n",
    "# json.dump(data,open('/tmp/poses_relative.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-29T11:36:44.399772",
     "start_time": "2016-11-29T11:36:44.392319"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # no doesn't work\n",
    "# data={}\n",
    "# pose_files = list(getpath.search(['data/poses'], ['.bvh'], True))\n",
    "# for pose_file in pose_files:\n",
    "#     bvh_obh = bvh.load(pose_file)\n",
    "#     pose_data=data[bvh_obh.name]={}\n",
    "#     for bone in bvh_obh.bvhJoints:\n",
    "#         m=bone.matRestGlobal\n",
    "#         pose_data[bone.name]=m.flatten().tolist()\n",
    "    \n",
    "\n",
    "# json.dump(data,open('/tmp/poses_global.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:08:11.175429",
     "start_time": "2016-12-12T17:08:04.540696"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export the normalised quarterions\n",
    "import transformations as tm\n",
    "# just the joints we need\n",
    "frame=0\n",
    "data={}\n",
    "pose_files = list(getpath.search(['data/poses'], ['.bvh'], True))\n",
    "for pose_file in pose_files:\n",
    "    bvh_obh = bvh.load(pose_file)\n",
    "    pose_data=data[bvh_obh.name]={}\n",
    "    bones=[b.name for b in bvh_obh.bvhJoints]\n",
    "    jointAnimList = [joint.name for joint in bvh_obh.getJoints() if not joint.isEndConnector()]\n",
    "    for i, name in enumerate(jointAnimList):        \n",
    "        bone = bvh_obh.bvhJoints[bones.index(name)]        \n",
    "        assert bone.name == name\n",
    "        \n",
    "        \n",
    "        quart = tm.quaternion_from_matrix(bone.matrixPoses[frame])\n",
    "        \n",
    "        quart = np.array([quart[1],quart[2],quart[3],quart[0]])\n",
    "        if np.abs(1-(quart**2).sum())>0.001:\n",
    "            print(name, (quart**2).sum())\n",
    "        pose_data[name]=quart.tolist()\n",
    "\n",
    "json.dump(data,open('/tmp/poses.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:18:22.409587",
     "start_time": "2016-12-12T17:18:22.407072"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.sys.path.append(basedir)\n",
    "from export_makehuman import copyAndCompress\n",
    "outdir = Path(basedir).joinpath('..','public','data','poses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:22:18.486486",
     "start_time": "2016-12-12T17:22:18.104671"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO copy thumbnail\n",
    "for pose_file in pose_files:\n",
    "    thumbnail = Path(pose_file.replace('.bvh','.thumb'))\n",
    "    outnail = outdir.joinpath(Path(thumbnail).basename()).replace('.thumb','.thumb.png')\n",
    "    \n",
    "    # copy thumbnail\n",
    "    if thumbnail.isfile():\n",
    "        copyAndCompress(thumbnail,outnail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# try setting poses then exporting - nope, same as exporting poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-29T11:36:50.138811",
     "start_time": "2016-11-29T11:36:44.436180"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # make base human model with helpers enabled\n",
    "# rigfile='data/rigs/default_no_toes.mhskel'\n",
    "\n",
    "# def getHuman():\n",
    "#     \"\"\"Load a human model with modifiers.\"\"\"\n",
    "#     with mhpath:\n",
    "#         # maxFaces *uint* Number of faces per vertex (pole), None for default (min 4)\n",
    "#         human = Human(files3d.loadMesh(\n",
    "#             getpath.getSysDataPath(\"3dobjs/base.obj\"),\n",
    "#             maxFaces=5))\n",
    "#         # load modifiers onto human\n",
    "#         humanmodifier.mods_loaded = False\n",
    "#         modifiers = humanmodifier.loadModifiers(\n",
    "#             getpath.getSysDataPath('modifiers/modeling_modifiers.json'), human)\n",
    "#         return human\n",
    "\n",
    "# with mhpath: \n",
    "#     basehuman = getHuman()\n",
    "    \n",
    "#     # rig\n",
    "#     if rigfile:\n",
    "#         humanargparser.addRig(basehuman,rigfile)    \n",
    "    \n",
    "#     mesh = basehuman.meshData\n",
    "#     group_mask = np.ones(len(mesh._faceGroups), dtype=bool)\n",
    "#     face_mask = group_mask[mesh.group]\n",
    "#     basehuman._staticFaceMask = face_mask\n",
    "#     basehuman.meshData.changeFaceMask(basehuman.staticFaceMask)\n",
    "#     basehuman.meshData.updateIndexBufferFaces()\n",
    "#     basehuman.changeVertexMask(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-20T11:39:54.397363",
     "start_time": "2016-11-20T11:39:53.862960"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data={}\n",
    "# pose_files = list(getpath.search(['data/poses'], ['.bvh'], True))\n",
    "# for pose_file in pose_files:\n",
    "#     bvh_obh = bvh.load(pose_file)\n",
    "#     pose_data=data[bvh_obh.name]={}\n",
    "#     for bone in bvh_obh.bvhJoints:\n",
    "#         m=np.identity(4, dtype=np.float32)\n",
    "#         m[:3]=bone.matrixPoses\n",
    "#         pose_data[bone.name]=m.flatten().tolist()\n",
    "        \n",
    "# data2={}\n",
    "# for pose_name in data:\n",
    "#     skeleton = basehuman.getSkeleton()\n",
    "#     matPoses = np.array(data['fight01'].values()).reshape((-1,4,4))\n",
    "#     skeleton.setPose(matPoses)\n",
    "#     pose_data=data2[bvh_obh.name]={}\n",
    "#     for bone in skeleton.bones.values():\n",
    "#         m = bone.matPose\n",
    "#         pose_data[bone.name]=m.flatten().tolist()\n",
    "\n",
    "# json.dump(data,open('/tmp/poses_through_skel.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-12T17:11:22.704421",
     "start_time": "2016-12-12T17:11:22.697537"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # export the normalised quarterions\n",
    "# import transformations as tm\n",
    "\n",
    "\n",
    "# # just the joints we need\n",
    "# jointAnimList = [joint.name for joint in bvh_obh.getJoints() if not joint.isEndConnector()]\n",
    "\n",
    "# frame=0\n",
    "# data={}\n",
    "# pose_files = list(getpath.search(['data/poses'], ['.bvh'], True))\n",
    "# for pose_file in pose_files:\n",
    "#     bvh_obh = bvh.load(pose_file)\n",
    "#     pose_data=data[bvh_obh.name]={}\n",
    "#     bones=[b.name for b in bvh_obh.bvhJoints]\n",
    "#     for i, name in enumerate(jointAnimList):        \n",
    "#         bone = bvh_obh.bvhJoints[bones.index(name)]\n",
    "#         assert bone.name == name\n",
    "# #         assert bone.rotOrder=='syzx', bone.rotOrder\n",
    "# #         assert bone.rotOrder=='szyx', bone.rotOrder\n",
    "        \n",
    "#         quart = tm.quaternion_from_matrix(bone.matrixPoses[frame])\n",
    "        \n",
    "#         quart = np.array([quart[1],quart[2],quart[3],quart[0]])\n",
    "#         quart=quart/quart.sum()\n",
    "#         pose_data[name]=quart.tolist()\n",
    "\n",
    "# json.dump(data,open('/tmp/poses_quart.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-29T13:21:32.359944",
     "start_time": "2016-11-29T13:21:32.356883"
    },
    "heading_collapsed": true
   },
   "source": [
    "# QC\n",
    "\n",
    "I have a problem in many poses with the leg and elbow, these are the joins that add to less the 0.9 as below. I'm now sure why or how to fix.\n",
    "\n",
    "Note rotOrder doesn't matter as it's adjusted for on load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-29T13:44:44.771781",
     "start_time": "2016-11-29T13:44:44.719865"
    },
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('upperleg01.R', 0.99999999999999956, -0.069166761370897611, [-0.5243, -0.0902, -0.2603, 0.8057])\n",
      "('upperleg02.R', 0.99999999999999989, 0.68513781362291948, [-0.165, -0.1418, 0.0161, 0.9759])\n",
      "('lowerleg02.R', 0.99999999999999956, 0.79853554953842243, [-0.0152, -0.1661, -0.0061, 0.986])\n",
      "('upperarm02.R', 1.0000000000000009, 0.63476654136876021, [-0.1595, -0.1798, 0.0034, 0.9707])\n",
      "('lowerarm01.L', 1.0000000000000002, 0.4033462473791618, [-0.2115, -0.318, 0.0086, 0.9242])\n",
      "('finger5-1.L', 1.0000000000000004, 0.72323297426417343, [0.0666, -0.0718, -0.2379, 0.9663])\n",
      "('finger4-1.L', 1.0000000000000002, 0.88216344560402959, [0.0739, -0.0472, -0.1319, 0.9874])\n",
      "('finger1-2.R', 0.99999999999999933, 0.84278011087238203, [-0.0276, -0.0945, -0.0298, 0.9947])\n",
      "('finger3-2.L', 1.0000000000000004, 0.82669275135918396, [0.1483, -0.1184, -0.1702, 0.967])\n",
      "('finger5-2.L', 1.0000000000000004, 0.79414246103043329, [0.0528, -0.0641, -0.1756, 0.981])\n",
      "('finger4-2.L', 1.0000000000000002, 0.75807875653706835, [0.1446, -0.1106, -0.2315, 0.9556])\n",
      "('finger5-3.L', 0.99999999999999989, 0.62483211282084294, [0.0899, -0.1017, -0.3058, 0.9424])\n",
      "('finger4-3.L', 0.99999999999999933, 0.77736812209144435, [0.1349, -0.0913, -0.2265, 0.9603])\n"
     ]
    }
   ],
   "source": [
    "# qc\n",
    "bvh_obh = bvh.load(u'data/poses/standing06.bvh')\n",
    "pose_data=data[bvh_obh.name]={}\n",
    "bones=[b.name for b in bvh_obh.bvhJoints]\n",
    "jointAnimList = [joint.name for joint in bvh_obh.getJoints() if not joint.isEndConnector()]\n",
    "for i, name in enumerate(jointAnimList):        \n",
    "    bone = bvh_obh.bvhJoints[bones.index(name)]    \n",
    "    assert bone.name == name\n",
    "\n",
    "    quart = tm.quaternion_from_matrix(bone.matrixPoses[frame])\n",
    "\n",
    "    quart = np.array([quart[1],quart[2],quart[3],quart[0]])\n",
    "    if quart.sum()<0.9:\n",
    "        print(name, (quart**2).sum(), quart.sum(),np.around(quart,4).tolist())\n",
    "    assert quart[3]>max(quart[0],quart[1],quart[2])\n",
    "    pose_data[name]=quart.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
